{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 CNN을 사용한 이미지 분류\n",
    "\n",
    "CNN은 합성곱으로 부터 ReLU 등의 활성화 함수를 적용하는 과정을 여러 번 실시하면 된다.\n",
    "컨벌루션 처리 후에 위치 감도를 높이는 pooling을 사용하거나 Dropout Batch Normalization을 사용하는 경우도 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm\n",
    "# tqdm은 진행상황을 바로 보여주는 것\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# 훈련용 데이터 가져오기 초기 상태에선 Python Imagin Library 이미지 형식으로 Dataset을 만들어버린다.\n",
    "# 따라서 transforms.ToTensor를 사용해 텐서로 변환\n",
    "fashion_mnist_train = FashionMNIST(\"/data/FashionMNIST\", train=True, download=True, transform=transforms.ToTensor())\n",
    "# 검증용 데이터 가져오기\n",
    "fashion_mnist_test = FashionMNIST(\"/data/FashionMNIST\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# 배치 크기가 128인 DataLoader를 각각 작성\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(fashion_mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(fashion_mnist_train, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (N, C, H, W)형식의 텐서를 (N, C*H*W)로 늘리는 계층\n",
    "# 합성곱 출력을 MLP에 전달할 때 필요\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "    \n",
    "# 5x5의 커널을 사용해서 처음에 32개 그다음에 64개 채널 작성\n",
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(1,32,5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout2d(0.25),\n",
    "    nn.Conv2d(32,64,5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    FlattenLayer()\n",
    ")\n",
    "\n",
    "# 합성곱에 의해 최종적으로 이미지 크기가 어떤지를 더미 데이터에 넣어서 확인한다.\n",
    "test_input = torch.ones(1, 1, 28, 28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]\n",
    "\n",
    "# 2층 MLP\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(conv_output_size, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200, 10)\n",
    ")\n",
    "\n",
    "# 최종 CNN\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.47020614300018704 0.83595 0.8963500261306763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.3164025517100962 0.8854333333333333 0.9110000133514404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.28151776765783626 0.8977333333333334 0.9212833642959595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.26058560078088033 0.90445 0.9319999814033508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.24455583670264125 0.90935 0.9354667067527771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.2353843532375291 0.9131333333333334 0.9345499873161316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2216096246599132 0.91765 0.9428499937057495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.212775170420989 0.9195 0.9432500004768372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.20382887570776492 0.9242666666666667 0.9446666836738586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:12<00:00, 38.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.19856960501553667 0.9268166666666666 0.9494667053222656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:13<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.19500191364851263 0.9271833333333334 0.9456000328063965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.18340955338735357 0.93215 0.9579333662986755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.1817306921713882 0.9318166666666666 0.9524666666984558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 42.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.17846622275841287 0.9331 0.9602000117301941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 41.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.17265802063843888 0.93605 0.9643333554267883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.16752417414234236 0.9375166666666667 0.9634833335876465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.16284647861766255 0.9385 0.9641333222389221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 40.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.1608779950815643 0.9386 0.9655333161354065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 41.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.15791023816340244 0.9403833333333333 0.9678333401679993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:11<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.15281154769353378 0.9424833333333333 0.9677166938781738\n"
     ]
    }
   ],
   "source": [
    "# 평가용 헬퍼 함수\n",
    "def eval_net(net, data_loader, device = \"cpu\"):\n",
    "    # Dropout및 BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x,y in data_loader:\n",
    "        # to 메소드로 계산을 실행할 디바이스로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 확률이 가장 큰 분류를 예측\n",
    "        # 여기선 forward(추론) 계산이 전부이므로 자동 미분에 필요한 처리는 off로 설정해서 불필요한 계산을 제한.\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "#훈련용 헬퍼 함수\n",
    "def train_net(net, train_loader, test_loader, optimizer_cls=optim.Adam, loss_fn=nn.CrossEntropyLoss(), n_iter=10, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 시간이 많이 걸리므로 tqdm을 사용해서 진행바를 표시\n",
    "        for i, (xx,yy) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 훈련 데이터의 예측 정확도\n",
    "        train_acc.append(n_acc / n)\n",
    "        \n",
    "        # 검증 데이터의 예측 정확도\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)\n",
    "\n",
    "# 신경망의 모든 파라미터 GPU로 전송\n",
    "net.to(\"cuda:0\")\n",
    "\n",
    "#훈련 실행\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 전이학습(Transfer Learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "# ImageFolder 함수를 사용해서 Dataset 작성\n",
    "train_imgs = ImageFolder(\"PyTorch_data/taco_and_burrito/train/\", transform=transforms.Compose([transforms.RandomCrop(224), \n",
    "                                                                                               transforms.ToTensor()]))\n",
    "test_imgs = ImageFolder(\"PyTorch_data/taco_and_burrito/test/\", transform=transforms.Compose([transforms.RandomCrop(224), \n",
    "                                                                                               transforms.ToTensor()]))\n",
    "# DataLoader 작성\n",
    "train_loader = DataLoader(train_imgs, batch_size=32, shuffle = True)\n",
    "test_loader = DataLoader(test_imgs, batch_size=32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ->  ['burrito', 'taco']\n"
     ]
    }
   ],
   "source": [
    "print('1 -> ', train_imgs.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ->  {'burrito': 0, 'taco': 1}\n"
     ]
    }
   ],
   "source": [
    "print('2 -> ', train_imgs.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# 사전 학습이 완료된 resnet18 불러오기\n",
    "net = models.resnet18(pretrained = True)\n",
    "# 모든 파라미터를 미분 대상에서 제외한다\n",
    "for p in net.parameters():\n",
    "    p.requres_grad = False\n",
    "\n",
    "# 마지막 선형 계층을 변경한다.\n",
    "fc_input_dim = net.fc.in_features\n",
    "net.fc = nn.Linear(fc_input_dim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:07<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6602973436767404 0.6348314606741573 0.7666667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5001959380778399 0.7879213483146067 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.4630606716329401 0.8061797752808989 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.40605021200396796 0.8300561797752809 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.3836274621161548 0.851123595505618 0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.3766575482758609 0.8398876404494382 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.3811285272240639 0.8356741573033708 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.3485623239116235 0.8665730337078652 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.36466838690367614 0.8609550561797753 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.3840279917825352 0.8497191011235955 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.3662467903711579 0.8441011235955056 0.8666667342185974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.3390463116494092 0.8623595505617978 0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.31807784736156464 0.8764044943820225 0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.31117289242419327 0.8820224719101124 0.9166666865348816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.33219807188619266 0.851123595505618 0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.31418624926697125 0.8679775280898876 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.35334083979780023 0.8595505617977528 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.3201365105130456 0.8609550561797753 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.29887542805888434 0.8890449438202247 0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.3002345995469527 0.8764044943820225 0.8833333849906921\n"
     ]
    }
   ],
   "source": [
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    # Dropout 및 BatchNorm 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        # to 메소드로 계산을 실행할 디바이스로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 확률이 가장 큰 분류를 예측\n",
    "        # 여기선 forward(추론) 계산이 전부이므로 자동 미분에 필요한 처리는 off로 설정해서 불필요한 계산을 제한다.\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    \n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys==ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "def train_net(net, train_loader, test_loader, only_fc = True, optimizer_cls=optim.Adam, \n",
    "              loss_fn=nn.CrossEntropyLoss(), n_iter=10, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    if only_fc:\n",
    "        optimizer = optimizer_cls(net.fc.parameters())\n",
    "    else:\n",
    "        optimizer = optimizer_cls(net.parameters())\n",
    "    \n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련 모드로 설정\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 시간이 많이 걸리므로 tqdm을 사용해서 진행 바를 표시\n",
    "        for i, (xx,yy) in tqdm.tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h,yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 훈련 데이터의 예측 정확도\n",
    "        train_acc.append(n_acc / n)\n",
    "        \n",
    "        # 검증 데이터의 예측 정확도\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush = True)\n",
    "        \n",
    "net.to(\"cuda:0\")\n",
    "\n",
    "# 훈련실행\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device = \"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 CNN 회귀 모델을 사용한 이미지 해상도 향상\n",
    "얼굴 이미지의 해상도를 향상시켜 본다.\n",
    "확대한 이미지를 bilinear와 CNN망을 통해 거친 이미지를 확인해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "class DownSizePairImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None, large_size=128, small_size=32, **kwds):\n",
    "        super().__init__(root, transform=transform, **kwds)\n",
    "        self.large_resizer = transforms.Resize(large_size)\n",
    "        self.small_resizer = transforms.Resize(small_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        \n",
    "        # 읽은 이미지를 128x128픽셀과 32x32픽셀로 리사이즈\n",
    "        large_img = self.large_resizer(img)\n",
    "        small_img = self.small_resizer(img)\n",
    "        \n",
    "        # 기타 변환 적용\n",
    "        if self.transform is not None:\n",
    "            large_img = self.transform(large_img)\n",
    "            small_img = self.transform(small_img)\n",
    "            \n",
    "        # 32픽셀의 이미지와 128 픽셀의 이미지 반환\n",
    "        return small_img, large_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DownSizePairImageFolder(\"PyTorch_data/lfw-deepfunneled/train\", transform=transforms.ToTensor())\n",
    "test_data = DownSizePairImageFolder(\"PyTorch_data/lfw-deepfunneled/test\", transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 256, 4, stride = 2, padding = 1),\n",
    "    nn. ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.Conv2d(256, 512, 4, stride = 2, padding = 1),\n",
    "    \n",
    "    nn. ReLU(),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "    nn. ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "    nn. ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "    nn. ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSNR 계산\n",
    "import math\n",
    "def psnr(mse, max_v = 1.0):\n",
    "    return 10 * math.log10(max_v**2 / mse)\n",
    "\n",
    "# 평가 헬퍼 함수\n",
    "def eval_net(net, data_loader, device = \"cpu\"):\n",
    "    # Dropout 및 BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x,y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = net(x)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    # 미니 배치 단위로 예측 결과 등을 하나로 모은다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    \n",
    "    # 예측 정확도(MSE) 계산\n",
    "    score = nn.functional.mse_loss(ypreds, ys).item()\n",
    "    return score\n",
    "\n",
    "# 훈련 헬퍼 함수\n",
    "def train_net(net, train_loader, test_loader, optimizer_cls = optim.Adam, loss_fn=nn.MSELoss(), n_iter=10, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련 모드로 설정\n",
    "        net.train()\n",
    "        n = 0\n",
    "        score = 0\n",
    "        # 시간이 많이 걸리므로 tqdm을 이용해서 진행 바 표시\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            y_pred = net(xx)\n",
    "            loss = loss_fn(y_pred, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], psnr(train_losses[-1]), psnr(val_acc[-1]), flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [01:00<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.025676979207431484 15.904560705841465 22.92659900570736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:58<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.00387565112982428 24.116553232650475 25.086853972260915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:59<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.003157963913075243 25.005928371022137 26.030373244828105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:58<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.0028866268956264105 25.396093462342932 26.1059282353742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:59<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.002739159284446452 25.623827124175335 25.954909320197164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:58<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.0025609167424215044 25.916045405845495 26.183185852473343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [01:00<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.002478377194505886 26.058325958509357 26.849119931933952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:59<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.002425537399963583 26.15192024491811 26.993737295052476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:59<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.002351158089346018 26.287181683985192 26.81978765596081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 409/409 [00:59<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.002296410654705646 26.389504467943446 26.871352218514303\n"
     ]
    }
   ],
   "source": [
    "net.to(\"cuda:0\")\n",
    "train_net(net, train_loader, test_loader, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "# 테스트 데이터로부터 랜덤으로 4개씩 추출하는 DataLoader\n",
    "random_test_loader = DataLoader(test_data, batch_size=4, shuffle=True)\n",
    "# DataLoader를 파이썬의 이터레이터로 변환해서 4개의 예로 추출\n",
    "it = iter(random_test_loader)\n",
    "x, y = next(it)\n",
    "\n",
    "# Bilinear를 사용한 확대\n",
    "bl_recon = torch.nn.functional.upsample(x, 128, mode=\"bilinear\", align_corners=True)\n",
    "# CNN으로 확대\n",
    "yp = net(x.to(\"cuda:0\")).to(\"cpu\")\n",
    "\n",
    "# torch.cat로 원본, Bilinear, CNN이미지를 결합하고 save_image로 결합한 이미지를 출력\n",
    "save_image(torch.cat([y, bl_recon, yp], 0), \"cnn_upscale.jpg\", nrow = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서의 nn.Sequential()은 Conv2d 두개, ConTransposed2d를 네개 연결한 CNN망이고 이것으로 이미지가 4배 확대된다.\n",
    "활성화 함수에 ReLU를 사용하고 Batch Normalization을 사용한다.\n",
    "원래 이미지와 확대한 이미지 사이의 MSE를 최소화 하기 위해 CNN을 훈련한다.\n",
    "음성이나 이미지에서는 MSE대신 PSNR이라는 말을 자주 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
