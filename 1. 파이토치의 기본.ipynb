{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.1 텐서 생성과 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "\n",
    "# 중첩 list를 지정\n",
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# device를 지정하면 GPU에 텐서를 만들 수 있다.\n",
    "t = torch.tensor([[1,2], [3, 4]], device = \"cuda:0\")\n",
    "\n",
    "# dtype을 사용해 데이터형을 지정하여 텐서를 만들 수 있다\n",
    "t = torch.tensor([[1,2], [3, 4]], dtype=torch.float64)\n",
    "\n",
    "t = torch.arange(0, 10)\n",
    "\n",
    "# 모든 값이 0인 100x10의 텐서를\n",
    "# 작성해서 to메서드로 GPU에 전송\n",
    "\n",
    "t = torch.zeros(100, 10).to(\"cuda:0\")\n",
    "t = torch.randn(100, 10)\n",
    "print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "x = t.numpy()\n",
    "\n",
    "t = torch.tensor([[1, 2], [3, 4]], device = \"cuda:0\")\n",
    "x = t.to(\"cpu\").numpy()\n",
    "print(x)\n",
    "#텐서의 Numpy는 GPU상 텐서는 그대로 변환할 수 없고 CPU로 이동후에 변환해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.2 텐서의 인덱스 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "cuda:0\n",
      "tensor([[ 1, 20,  3],\n",
      "        [ 4, 20,  6]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t[0,2]\n",
    "t[:,:2]\n",
    "print(t)\n",
    "t[:,[1,2]]\n",
    "t[t>3]\n",
    "t[0 ,1] = 100\n",
    "t[:,1] = 200\n",
    "t[t>10] = 20\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.3 텐서연산\n",
    "## 대규모 데이터를 처리할 때 GPU를 사용하기 때문에 조금 더 빠르게 처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11., 12., 13.])\n"
     ]
    }
   ],
   "source": [
    "# 길이가 3인 벡터\n",
    "v = torch.tensor([1,2,3.])\n",
    "w = torch.tensor([0,10,20.])\n",
    "# 2x3의 행렬\n",
    "m = torch.tensor([[0,1,2],[100,200,300]])\n",
    "# 벡터와 스칼라의 덧셈\n",
    "v2 = v + 10\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 9.])\n"
     ]
    }
   ],
   "source": [
    "# **의 경우 제곱을 의미\n",
    "v2 = v**2\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.,  -8., -17.])\n"
     ]
    }
   ],
   "source": [
    "# 동일 길이 벡터 간 뺄셈\n",
    "z = v-w\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   2,   4],\n",
      "        [200, 400, 600]])\n"
     ]
    }
   ],
   "source": [
    "m3 = m + m\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3505, -0.9197,  0.2431,  0.0525, -0.2246],\n",
      "        [-0.0027, -0.1374, -1.7721,  0.1659, -0.2148],\n",
      "        [-1.1342, -1.6556, -2.2396, -0.5513,  0.6070],\n",
      "        [-1.3371,  0.1129, -1.9381,  0.6667,  0.6990],\n",
      "        [-0.2455, -0.5073, -1.3586, -0.4287,  0.2208]])\n",
      "tensor([[-0.3505, -0.9197,  0.7293,  0.1576, -0.2246],\n",
      "        [-0.0027, -0.1374, -1.7721,  0.4976, -0.2148],\n",
      "        [-1.1342, -1.6556, -2.2396, -0.5513,  1.8210],\n",
      "        [-1.3371,  0.3388, -1.9381,  2.0002,  2.0971],\n",
      "        [-0.2455, -0.5073, -1.3586, -0.4287,  0.6624]])\n",
      "tensor(-0.4900)\n",
      "tensor([-0.6140, -0.6214, -1.4131, -0.0190,  0.2175])\n"
     ]
    }
   ],
   "source": [
    "# 5x5의 테스트 데이터 생성\n",
    "x = torch.randn(5,5)\n",
    "print(x)\n",
    "# 수학 함수를 포함하는 수식\n",
    "y = x*2 + torch.abs(x)\n",
    "print(y)\n",
    "# 평균치 구하기\n",
    "m = torch.mean(x)\n",
    "print(m)\n",
    "\n",
    "m_value = m.item()\n",
    "m2 = x.mean(0)\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 텐서와 자동 미분\n",
    "## 텐서에는 requires_grad라는 속성이 있어서 True로 설정하면 자동 미분 기능 활성화 여기에 backward 메소드를 호출하면 그래프로부터 자동으로 미분 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(100, 3)\n",
    "a = torch.tensor([1,2,3.], requires_grad = True)\n",
    "\n",
    "y = torch.mv(x,a)\n",
    "o = y.sum()\n",
    "\n",
    "o.backward()\n",
    "\n",
    "a.grad != x.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
